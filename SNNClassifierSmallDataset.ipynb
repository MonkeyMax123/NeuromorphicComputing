{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10645fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import nengo_dl\n",
    "from PIL import Image\n",
    "from timeit import default_timer as timer\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b7e194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is the sample SNN provided by Nengo with the Conv2D layer sizes changed to accomodate our images\n",
    "with nengo.Network(seed=0) as net:\n",
    "    # set some default parameters for the neurons that will make\n",
    "    # the training progress more smooth\n",
    "    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([100])\n",
    "    net.config[nengo.Ensemble].intercepts = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    neuron_type = nengo.LIF(amplitude=0.01)\n",
    "\n",
    "    # this is an optimization to improve the training speed,\n",
    "    # since we won't require stateful behaviour\n",
    "    nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # the input node that will be used to feed in input images\n",
    "    inp = nengo.Node(np.zeros(224*224*4))\n",
    "\n",
    "    # add the first convolutional layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Conv2D(filters=32, strides=2, kernel_size=3))(\n",
    "        inp, shape_in=(224, 224, 4)\n",
    "    )\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # add the second convolutional layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Conv2D(filters=64, strides=2, kernel_size=3))(\n",
    "        x, shape_in=(111, 111, 32)\n",
    "    )\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # add the third convolutional layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Conv2D(filters=128, strides=2, kernel_size=3))(\n",
    "        x, shape_in=(55, 55, 64)\n",
    "    )\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Conv2D(filters=128, strides=2, kernel_size=3))(\n",
    "    x, shape_in=(27, 27, 128)\n",
    "    )\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "    \n",
    "    # linear readout\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Flatten())(x)\n",
    "    out = nengo_dl.Layer(tf.keras.layers.Dense(units=4))(x)\n",
    "\n",
    "    # we'll create two different output probes, one with a filter\n",
    "    # (for when we're simulating the network over time and\n",
    "    # accumulating spikes), and one without (for when we're\n",
    "    # training the network using a rate-based approximation)\n",
    "    out_p = nengo.Probe(out, label=\"out_p\")\n",
    "    out_p_filt = nengo.Probe(out, synapse=0.1, label=\"out_p_filt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a087c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:04                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:01                                               \n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 50\n",
    "sim = nengo_dl.Simulator(net, minibatch_size=minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281ae71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Access the parent folder\n",
    "parent_folder = os.path.join(current_directory, 'streetsign')\n",
    "\n",
    "#Create Images and Labels folders\n",
    "image_folder = os.path.join(parent_folder, 'images')\n",
    "labels_folder = os.path.join(parent_folder, 'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1b63e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store features (X) and labels (y)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate over image files\n",
    "for image_file in os.listdir(image_folder):\n",
    "    # Load Image\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "\n",
    "    X.append(np.asarray(image))\n",
    "\n",
    "    # Extract corresponding label from the XML annotation\n",
    "    label_file = os.path.join(labels_folder, image_file.replace('.png', '.xml'))\n",
    "    tree = ET.parse(label_file)\n",
    "    root = tree.getroot()\n",
    "    class_label = root.find('.//object/name').text\n",
    "    if class_label == 'speedlimit':\n",
    "        class_label = 0\n",
    "    elif class_label == 'stop':\n",
    "        class_label = 1\n",
    "    elif class_label == 'crosswalk':\n",
    "        class_label = 2\n",
    "    elif class_label == 'trafficlight':\n",
    "        class_label = 3\n",
    "    y.append(class_label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "train_images = train_images.reshape((train_images.shape[0], -1))\n",
    "test_images = test_images.reshape((test_images.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "861d8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add single timestep to training data\n",
    "train_images = train_images[:, None, :]\n",
    "train_labels = train_labels[:, None, None]\n",
    "\n",
    "# when testing our network with spiking neurons we will need to run it\n",
    "# over time, so we repeat the input/target data for a number of\n",
    "# timesteps.\n",
    "n_steps = 30\n",
    "test_images = np.tile(test_images[:, None, :], (1, n_steps, 1))\n",
    "test_labels = np.tile(test_labels[:, None, None], (1, n_steps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1f984ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Timer\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\NeuromorphicComputing\\lib\\site-packages\\nengo_dl\\simulator.py:1893: UserWarning: Number of elements in input data (220) is not evenly divisible by Simulator.minibatch_size (50); input data will be truncated.\n",
      "  f\"Number of elements in input data ({data_batch}) is not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training: 0.10499999672174454:00:00                            \n",
      "Time to Run:  382.8517517999999\n"
     ]
    }
   ],
   "source": [
    "def classification_accuracy(y_true, y_pred):\n",
    "    return tf.metrics.sparse_categorical_accuracy(y_true[:, -1], y_pred[:, -1])\n",
    "\n",
    "start = timer()\n",
    "print(\"Starting Timer\")\n",
    "# note that we use `out_p_filt` when testing (to reduce the spike noise)\n",
    "sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "print(\n",
    "    \"Accuracy before training:\",\n",
    "    sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"],\n",
    ")\n",
    "end = timer()\n",
    "print(\"Time to Run: \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "080aa10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\NeuromorphicComputing\\lib\\site-packages\\nengo_dl\\simulator.py:1893: UserWarning: Number of elements in input data (657) is not evenly divisible by Simulator.minibatch_size (50); input data will be truncated.\n",
      "  f\"Number of elements in input data ({data_batch}) is not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 69s 4s/step - loss: 4.1889 - out_p_loss: 4.1889\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 51s 4s/step - loss: 1.0308 - out_p_loss: 1.0308\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 51s 4s/step - loss: 0.9395 - out_p_loss: 0.9395\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.9835 - out_p_loss: 0.9835\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 51s 4s/step - loss: 0.7960 - out_p_loss: 0.7960\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.8721 - out_p_loss: 0.8721\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.8804 - out_p_loss: 0.8804\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 51s 4s/step - loss: 0.8112 - out_p_loss: 0.8112\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.7211 - out_p_loss: 0.7211\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 51s 4s/step - loss: 0.7569 - out_p_loss: 0.7569\n",
      "Time to Trian:  534.8996397999999\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "do_training = True\n",
    "if do_training:\n",
    "    # run training\n",
    "    sim.compile(\n",
    "        optimizer=tf.optimizers.RMSprop(0.001),\n",
    "        loss={out_p: tf.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    )\n",
    "    sim.fit(train_images, {out_p: train_labels}, epochs=10)\n",
    "    end = timer()\n",
    "    print(\"Time to Trian: \", (end - start))\n",
    "    # save the parameters to file\n",
    "    sim.save_params(\"./streetsigns_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68727d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\NeuromorphicComputing\\lib\\site-packages\\nengo_dl\\simulator.py:2070: RuntimeWarning: Simulator with model=Model: <Network (unlabeled) at 0x25a75dfc448>, dt=0.001000 was deallocated while open. Simulators should be closed manually to ensure resources are properly freed.\n",
      "  RuntimeWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after training: 0.7200000286102295 0:00:00                            \n",
      "Time to Run:  302.3334097000002\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "print(\n",
    "    \"Accuracy after training:\",\n",
    "    sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"],\n",
    ")\n",
    "end = timer()\n",
    "print(\"Time to Run: \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8b28d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9d50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
